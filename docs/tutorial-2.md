#### Understanding the outputs

##### Logs
Once we run the previous example, things like these are logged and showed in the terminal:

```
2021-04-12 16:59:02,809 — Paips — INFO — Gathering tasks for MainTask
2021-04-12 16:59:02,813 — Paips — INFO — MainTask: Hash f4d0e5dbb37a662871f6d09f31fc854cb23f3ef1
2021-04-12 16:59:02,814 — Paips — INFO — MainTask: Running
2021-04-12 16:59:02,814 — Paips — INFO — ReadCSV: Hash 1a6c275b4cd933f9a1915eca07dce534df5e32e4
2021-04-12 16:59:02,815 — Paips — INFO — ReadCSV: Running
2021-04-12 16:59:03,434 — Paips — INFO — ReadCSV: Saving outputs
2021-04-12 16:59:03,440 — Paips — INFO — TrainValTestPartition: Hash e5728bea9009ec8d42140efd3b871f589d061119
2021-04-12 16:59:03,440 — Paips — INFO — TrainValTestPartition: Running
2021-04-12 16:59:03,443 — Paips — INFO — TrainValTestPartition: Saving outputs
2021-04-12 16:59:03,450 — Paips — INFO — MainTask: Saving outputs
```

So, we have the time when each task was executed, a unique hash to identify each task, and messages about each task being ran or its output saved.

##### Caching and In Memory
Some questions arise: Why are all tasks saving outputs? Can we avoid it? Where are those outputs saved?

By default, the output of each task is serialized using **joblib** and saved in the <cache_folder>/<task_hash> directory.

Let's do a little experiment and run again:

```paiprun configs/ex1.yaml```

Now, this gets printed:

```
2021-04-12 16:59:39,787 — Paips — INFO — Gathering tasks for MainTask
2021-04-12 16:59:39,792 — Paips — INFO — MainTask: Hash 63fd16edb7cd985938e5c30518cc6fae16770e1f
2021-04-12 16:59:39,792 — Paips — INFO — MainTask: Running
2021-04-12 16:59:39,793 — Paips — INFO — ReadCSV: Hash 1a6c275b4cd933f9a1915eca07dce534df5e32e4
2021-04-12 16:59:39,794 — Paips — INFO — ReadCSV: Caching
2021-04-12 16:59:39,798 — Paips — INFO — TrainValTestPartition: Hash e5728bea9009ec8d42140efd3b871f589d061119
2021-04-12 16:59:39,798 — Paips — INFO — TrainValTestPartition: Caching
2021-04-12 16:59:39,800 — Paips — INFO — MainTask: Saving outputs
```

Now, ReadCSV and TrainValTestPartition are not 'Running' nor 'Saving outputs'. Welcome to the world of **Cache**

This is what is happening under the hood. Before running the **process()** method of each task, a hash is generated from all the task parameters. Then, before running **process()**, we take a look inside the **cache** folder and see if <cache_folder>/<task_hash> exists. If it exists, instead of running again **process()**, we just load the saved outputs. This is really useful when a task takes a very long time and we don't want to run it again and again. 
We can change the default <cache_folder> by adding this to our config:

```yaml
global:
  cache_path: <new_cache_folder>
```

However, some times we might want to regenerate the outputs and avoid caching. In that case, we can deactivate caching for a particular task adding the parameter:

```yaml
cache: False
```

or we can deactivate caching for all tasks adding the following argument when calling paiprun:

```
paiprun configs/ex1.yaml --no-caching
```

In those cases, the **process()** method is called regardless of if <cache_folder>/<task_hash> exists or not. If it exists, it will be replaced by the new outputs.

Another useful parameter that can be added to any task is:

```yaml
in_memory: False
```

This way, the task not only will not be cached, but also, outputs won't be saved in disk and instead will be stored in memory until no other task needs them. This is useful when the tasks don't take too long (to avoid saving unnecessary files), and we want them to run very fast (because saving/loading from disk takes some time).

##### Generated Files

Let's take a look at the files generated by running the experiment. You should see something like this in the samples folder:

```
├── cache
│   ├── 1a6c275b4cd933f9a1915eca07dce534df5e32e4_0
│   ├── 63fd16edb7cd985938e5c30518cc6fae16770e1f_0
│   ├── e5728bea9009ec8d42140efd3b871f589d061119_0
│   ├── e5728bea9009ec8d42140efd3b871f589d061119_1
│   ├── e5728bea9009ec8d42140efd3b871f589d061119_2
│   └── f4d0e5dbb37a662871f6d09f31fc854cb23f3ef1_0
├── configs
├── experiments
│   ├── 2021-04-12 16:59:02
│   │   ├── MainTask
│   │   │   ├── ReadCSV
│   │   │   └── TrainValTestPartition
│   │   └── configs
│   └── 2021-04-12 16:59:39
│       ├── MainTask
│       │   ├── ReadCSV
│       │   └── TrainValTestPartition
│       └── configs
└── tasks
```

experiments and tasks folders already existed. cache folder is where all the outputs were saved. Each of its subfolders are <task_hash>_<i> where i is the position of the output in the **process()** return. This is to identify different outputs from a same task. Inside of each of these subfolders you will find a file without extension, like **out** or **train**. The name of that file corresponds to the name of the task output (remember what was on the right of the ->).
Then, we have the experiments folder, which has 2 subfolders. Each of those subfolders correspond to the 2 times we called paiprun. By default, the name of the folder is the time when the experiment was executed. We can change those directories names easily: just add the --output_path argument in the paiprun call:
  
```
paiprun configs/ex1.yaml --output_path 'my_experiments/my_first_experiment'
```

This way you can better organize your experiments.

Now, let's take a look at what is inside each of the experiments. There are 2 folders: MainTask and configs.
MainTask is the name the task corresponding to executing the whole pipeline receives. Later, we will dive deeper into this concept of the pipeline being also a task.

In configs you will find:

```
── configs
 ├── MainTask.yaml
 ├── ReadCSV.yaml
 └── TrainValTestPartition.yaml
```
These are configuration files generated from the main configuration file 'ex1.yaml'. They can help you to keep track of what parameters each task received, and when doing configuration files composition (more on that later) it can be helpful for debugging.

Then, in the MainTask folder you will find several subfolders. Each one corresponds to a task:

```
│   │   ├── MainTask
│   │   │   ├── ReadCSV
│   │   │   │   └── out -> /home/ubuntu/paips/samples/cache/1a6c275b4cd933f9a1915eca07dce534df5e32e4_0/out
│   │   │   ├── TrainValTestPartition
│   │   │   │   ├── test
│   │   │   │   ├── train
│   │   │   │   └── validation
│   │   │   └── out -> /home/ubuntu/paips/samples/cache/f4d0e5dbb37a662871f6d09f31fc854cb23f3ef1_0/out
```
The outputs of each task appear inside the folders. These outputs can either be symbolic links to the location in <cache_folder> where the output is stored, or the actual files if we set export=True.

Finally, there is also a links.txt file, which basically shows where each of the symbolic links from the experiment points to.

##### Loading the outputs

As mentioned earlier, outputs are serialized using joblib, so the way to open them is by running in your notebook/python code something like:

```
import joblib

mydata = joblib.load('experiments/2021-04-12 16:59:02/MainTask/TrainValTestPartition/test')
```

And this will give you the saved dataframe with data corresponding to the test partition:
```
      fixed acidity  volatile acidity  citric acid  residual sugar  ...    pH  sulphates  alcohol  quality
5               7.4             0.660         0.00             1.8  ...  3.51       0.56      9.4        5
13              7.8             0.610         0.29             1.6  ...  3.26       1.56      9.1        5
15              8.9             0.620         0.19             3.9  ...  3.17       0.93      9.2        5
23              8.5             0.490         0.11             2.3  ...  3.17       0.53      9.4        5
26              7.6             0.410         0.24             1.8  ...  3.28       0.59      9.5        5
...             ...               ...          ...             ...  ...   ...        ...      ...      ...
1576            8.0             0.300         0.63             1.6  ...  3.30       0.78     10.8        6
1577            6.2             0.700         0.15             5.1  ...  3.54       0.60     11.9        6
1586            7.5             0.310         0.41             2.4  ...  3.34       0.85     11.4        6
1589            6.6             0.725         0.20             7.8  ...  3.29       0.54      9.2        5
1596            6.3             0.510         0.13             2.3  ...  3.42       0.75     11.0        6

[321 rows x 12 columns]
```
